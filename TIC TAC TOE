import numpy as np
import random

# =====================================================
# TIC-TAC-TOE ENVIRONMENT
# =====================================================
class TicTacToe:
    def __init__(self):
        self.reset()

    def reset(self):
        self.board = np.zeros(9)
        self.done = False
        return self.board.copy()

    def available_actions(self):
        return [i for i in range(9) if self.board[i] == 0]

    def step(self, action, player):
        self.board[action] = player
        reward, self.done = self.check_winner()
        return self.board.copy(), reward, self.done

    def check_winner(self):
        win_positions = [
            [0,1,2],[3,4,5],[6,7,8],
            [0,3,6],[1,4,7],[2,5,8],
            [0,4,8],[2,4,6]
        ]

        for pos in win_positions:
            total = sum(self.board[pos])
            if total == 3:
                return 1, True
            if total == -3:
                return -1, True

        if 0 not in self.board:
            return 0, True

        return 0, False


# =====================================================
# VANILLA POLICY GRADIENT AGENT
# =====================================================
class PolicyGradientAgent:
    def __init__(self, learning_rate=0.01):
        self.lr = learning_rate
        self.weights = np.random.randn(9, 9) * 0.01

    def softmax(self, x):
        exp_x = np.exp(x - np.max(x))
        return exp_x / np.sum(exp_x)

    def choose_action(self, state):
        logits = state @ self.weights
        probs = self.softmax(logits)

        valid_actions = [i for i in range(9) if state[i] == 0]
        masked_probs = np.zeros(9)
        masked_probs[valid_actions] = probs[valid_actions]
        masked_probs /= masked_probs.sum()

        action = np.random.choice(9, p=masked_probs)
        return action

    def update_policy(self, states, actions, rewards):
        G = 0
        for t in reversed(range(len(states))):
            G += rewards[t]
            state = states[t]
            action = actions[t]

            logits = state @ self.weights
            probs = self.softmax(logits)

            grad = -probs
            grad[action] += 1
            self.weights += self.lr * G * np.outer(state, grad)


# =====================================================
# TRAINING THE AGENT
# =====================================================
env = TicTacToe()
agent = PolicyGradientAgent()

episodes = 5000

for episode in range(episodes):
    state = env.reset()
    states, actions, rewards = [], [], []

    while True:
        action = agent.choose_action(state)
        next_state, reward, done = env.step(action, 1)

        states.append(state)
        actions.append(action)
        rewards.append(reward)

        if done:
            agent.update_policy(states, actions, rewards)
            break

        opponent_action = random.choice(env.available_actions())
        next_state, reward, done = env.step(opponent_action, -1)

        rewards[-1] = reward
        state = next_state

        if done:
            agent.update_policy(states, actions, rewards)
            break

print("Training completed successfully!")


# =====================================================
# HUMAN vs AGENT GAMEPLAY
# =====================================================
def print_board(board):
    symbols = {0: ".", 1: "X", -1: "O"}
    for i in range(0, 9, 3):
        print(" ".join(symbols[int(board[i+j])] for j in range(3)))
    print()

state = env.reset()
print("You are O | Agent is X")
print("Positions are numbered 0 to 8\n")

while True:
    print_board(state)

    human_move = int(input("Enter your move (0-8): "))
    state, reward, done = env.step(human_move, -1)

    if done:
        print_board(state)
        if reward == -1:
            print("üéâ You Win!")
        else:
            print("ü§ù Draw!")
        break

    agent_move = agent.choose_action(state)
    state, reward, done = env.step(agent_move, 1)

    if done:
        print_board(state)
        if reward == 1:
            print("ü§ñ Agent Wins!")
        else:
            print("ü§ù Draw!")
        break
